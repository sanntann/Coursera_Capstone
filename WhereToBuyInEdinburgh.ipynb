{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbourhood insights for buying a home in Edinburgh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents  \n",
    "- [Introduction](#introduction)\n",
    "- [Business problem](#introduction.business_problem)\n",
    "    - [Static ranking system](#introduction.static_ranking_system)\n",
    "    - [Dynamic ranking system](#introduction.dynamic_ranking_system)\n",
    "- [Data](#data)\n",
    "    - [Overview](#data.overview)\n",
    "    - [Foursquare venue data](#data.foursquare_venue_data)\n",
    "    - [Rightmove property sale price data](#data.rightmove_property_sale_price_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"/>\n",
    "\n",
    "### Business problem <a name=\"introduction.business_problem\"/>\n",
    "\n",
    "A major estate agent in **Edinburgh** would like to provide more information about neighbourhoods to their clients. Local amenities are very important in deciding to buy a home, in addition to the property itself. This information, however, is not provided by the estate agent to the same quality as details about the property itself. **Presenting valuable insights about local amenities to potential buyers could attract more customers,** particularly those new to the city.\n",
    "\n",
    "The insights about local amenities should be provided to the home buyer in a format that can be directly used in making their decision. Firstly, the information should be easy and quick to understand. Secondly, it should allow intuitive comparison between available properties. Thirdly, it should be objective truth, based on statistics, and not a biased opinion.\n",
    "\n",
    "**This project aims to provide a solution for informing home buyers about the neighbourhoods in Edinburgh.** We will achieve this by generating two ranking systems. Firstly, **a static ranking system** for common preference types, such as favouring nightlife venues over parks or grocery stores over restaurants. Secondly, **a dynamic ranking system** that provides a ranking of neighbourhoods based on the client's personal preferences and purchase price range.\n",
    "\n",
    "### Static ranking system <a name=\"introduction.static_ranking_system\"/>\n",
    "\n",
    "The static ranking system will be created using **k-means clustering** of neighbourhoods based on the local amenities and identifying preference categories in the resulting clusters.\n",
    "\n",
    "### Dynamic ranking system <a name=\"introduction.dynamic_ranking_system\"/>\n",
    "\n",
    "The dynamic ranking system will be ranking how well each neighbourhood matches the ideal neighbourhood based on user preferences. User input will be quantified relative to the **distribution of each feature across all neighbourhoods**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name=\"data\"/>\n",
    "\n",
    "### Overview <a name=\"data.overview\"/>\n",
    "\n",
    "For this project we will need data on venues and amenities across Edinburgh and property sale price data. We will acquire the data on venues and amenities using Foursqare API. The sale price data will be acquired using web scraping on Rightmove website.\n",
    "\n",
    "The neighbourhoods will be overlapping circular grid fields positioned uniformly across Edinburgh. All venues will be assigned to and mean property sale prices will be computed for these artifical neighbourhoods. These neighbourhoods with the resulting features will be the subject of the statistical and machine learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foursquare venue data <a name=\"data.foursquare_venue_data\"/>\n",
    "\n",
    "Foursquare only returns 50 venues per request, therefore, to get detailed data on venues and amenities each neighbourhood, we need to use multiple requests.\n",
    "\n",
    "We will compute uniformly distributed positions across Edinburgh that will be the center points of our Foursquare API calls to collect locations of all the venues in categories of interest (e.g. cafe, turkish restaurant, night club, grocery store, gym).\n",
    "\n",
    "We will arrange these examples into a `pandas.DataFrame` that will contain venue category, rating, latitude and longitude.\n",
    "\n",
    "The interface with the Foursqare API will be re-using the code in [my Assessment 3 submission](https://nbviewer.jupyter.org/github/sanntann/Coursera_Capstone/blob/master/Assessment_3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rightmove property sale price data <a name=\"data.rightmove_property_sale_price_data\"/>\n",
    "\n",
    "Rightmove is a major UK property website. They provide a list of sale price data going back several years. \n",
    "\n",
    "For some of the properties on the list there is a link to a post on Rightmove website and information on the type of the property, including number of bedrooms. As the latter information is a major determinant of sale price, we will only use data on properties where this information is available. This will allow more client preference specific estimation of mean property prices in neighbourhoods.\n",
    "\n",
    "Rightmove provides the address for each property, including the postcode. We will use a Edinburgh postcode latitude and longitude dataset to approximate the latitude and longitude of each property. This will allow assigning each property to one of the artificial neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load Edinburgh Postcode table that contains latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('EdinburghPostcodes.csv'):\n",
    "    # If the file is not available on disk, download it\n",
    "    urlretrieve ('https://www.doogal.co.uk/AdministrativeAreasCSV.ashx?district=S12000036', 'EdinburghPostcodes.csv')\n",
    "df_postcodes = pd.read_csv('EdinburghPostcodes.csv', usecols=['Postcode', 'Latitude', 'Longitude'])\n",
    "df_postcodes.columns = map(str.lower, df_postcodes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function the extract data for properties from a BeautifulSoup of a html webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_type_from_sold_property_page(http_address):\n",
    "    soup = BeautifulSoup(get(http_address).text, 'html.parser')\n",
    "    return soup.find(id='propertydetails').find_all('h2')[1].text\n",
    "\n",
    "\n",
    "def get_property_data_from_soup(soup):\n",
    "    # Extract data from the http soup\n",
    "    date = []\n",
    "    address = []\n",
    "    bedrooms = []\n",
    "    price = []\n",
    "    property_type = []\n",
    "    for soup_property in soup.find_all(class_='soldDetails'):\n",
    "        # Skip properties for which there is no link to post on RightMove website\n",
    "        if not soup_property.find(class_='soldAddress').has_attr('href'):\n",
    "            continue\n",
    "        else:\n",
    "            property_http_address = soup_property.find(class_='soldAddress')['href']\n",
    "        # Skip properties for which there is no number of bedrooms information\n",
    "        if len(soup_property.find(class_='noBed').text) == 0:\n",
    "            continue\n",
    "        # Collect data for the property\n",
    "        date.append(soup_property.find(class_='soldDate').text)\n",
    "        address.append(soup_property.find(class_='soldAddress').text)\n",
    "        bedrooms.append(soup_property.find(class_='noBed').text)\n",
    "        price.append(soup_property.find(class_='soldPrice').text)\n",
    "        # Attempt to collect property type\n",
    "        try:\n",
    "            property_type.append(get_property_type_from_sold_property_page(property_http_address))        \n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            raise\n",
    "        except:\n",
    "            property_type.append('')\n",
    "            print('Error when collecting property type.')\n",
    "            print(sys.exc_info()[0])\n",
    "    # Format data into pandas.DataFrame\n",
    "    df = pd.DataFrame({'date': date, \n",
    "                       'address': address, \n",
    "                       'bedrooms': bedrooms, \n",
    "                       'property_type': property_type, \n",
    "                       'price': price}, \n",
    "                      columns=['date', 'address', 'bedrooms', 'property_type', 'price'])\n",
    "    # Sort the DataFrame by date as well as address\n",
    "    df.sort_values(['date', 'address'], ascending=[False, True], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class to manage web scraping rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "\n",
    "class RateManager(object):\n",
    "    \n",
    "    def __init__(self, min_interval, max_interval):\n",
    "        \"\"\"\n",
    "        min_interval - float - minimum delay between calls (in seconds)\n",
    "        max_interval - float - maximum delay between calls before notification (in seconds)\n",
    "        \"\"\"\n",
    "        self.min_interval = min_interval\n",
    "        self.max_interval = max_interval\n",
    "        self.checkpoint = None\n",
    "        \n",
    "    def continue_when_ready(self, sleep_interval=0.1, print_interval=False):\n",
    "        # This is in case of first call to continue_when_ready\n",
    "        if self.checkpoint is None:\n",
    "            self.checkpoint = time()\n",
    "            return None\n",
    "        # Check if max_interval has been surpassed\n",
    "        if time() - self.checkpoint > self.max_interval:\n",
    "            if print_interval:\n",
    "                print('Interval duration: {}'.format(time() - self.checkpoint))\n",
    "            self.checkpoint = time()\n",
    "            return 'timeout'\n",
    "        # If not over max_interval, wait until min_interval is reached\n",
    "        if print_interval:\n",
    "            print('Interval duration: {}'.format(time() - self.checkpoint))\n",
    "        while time() - self.checkpoint < self.min_interval:\n",
    "            sleep(sleep_interval)\n",
    "        self.checkpoint = time()\n",
    "        return 'intime'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire residential property sales prices from RightMove.\n",
    "\n",
    "There are likely duplicates in the resulting DataFrame. These will be dealt with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected total of 2952 properties from RightMove.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('EdinburghPropertiesRaw.p'):\n",
    "    # If the script has already been run, load the result from disk\n",
    "    df_property = pd.read_pickle('EdinburghPropertiesRaw.p')\n",
    "else:\n",
    "    # List the http addresses for different areas of interest in Edinburgh\n",
    "    http_addresses = {\n",
    "        'Stockbridge': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E66977&searchLocation=Stockbridge&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "        'NewTown': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E79909&searchLocation=New+Town&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "        'Morningside': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E86881&searchLocation=Morningside&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "        'EdinburghNorth': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E93604&searchLocation=Edinburgh+North&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "        'EdinburghEast': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E93601&searchLocation=Edinburgh+East&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "        'EdinburghWest': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E93613&searchLocation=Edinburgh+West&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "        'EdinburghSouth': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E93610&searchLocation=Edinburgh+South&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "        'Edinburgh': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E475&searchLocation=Edinburgh&propertyType=3&year=2&referrer=listChangeCriteria'\n",
    "        }\n",
    "\n",
    "    # Specify in-line function for suffix that specifies property list page index\n",
    "    http_index_suffix = lambda index: '&index={}'.format(index)\n",
    "\n",
    "    # Specify indices to work through\n",
    "    indices = list(range(0, 1025, 25))\n",
    "\n",
    "    # Create empty pandas.DataFrame to append new data to\n",
    "    df_property = pd.DataFrame({'date': [], \n",
    "                                'address': [], \n",
    "                                'bedrooms': [], \n",
    "                                'property_type': [], \n",
    "                                'price': []}, \n",
    "                               columns=['date', 'address', 'bedrooms', 'property_type', 'price'])\n",
    "\n",
    "    # Use RateManager to avoid overwhelming the website\n",
    "    rate_manager = RateManager(min_interval=5, max_interval=20)\n",
    "    max_timeouts = 10\n",
    "    timeout_count = 0\n",
    "\n",
    "    # Loop through all http addresses of different areas and all possible page indices\n",
    "    df_prev_property_list = pd.DataFrame({})\n",
    "    for http_address in [http_addresses[x] for x in http_addresses]:\n",
    "        for index in indices:\n",
    "            full_http_address = http_address + http_index_suffix(index)\n",
    "            print('Visiting webpage:\\n' + full_http_address)\n",
    "            # Make sure webpage is not visited too often and that it is not blocking\n",
    "            if rate_manager.continue_when_ready(print_interval=True) == 'timeout':\n",
    "                timeout_count += 1\n",
    "                if timeout_count > max_timeouts:\n",
    "                    raise RuntimeError('Too many timeouts.')\n",
    "            # Get website html as BeautifulSoup\n",
    "            soup = BeautifulSoup(get(full_http_address).text, 'html.parser')\n",
    "            # Check if there is a property price data list on this page\n",
    "            if len(soup.find_all(class_='soldDetails')) == 0:\n",
    "                print('No properties listed on this page. Stopping index iteration.')\n",
    "                break\n",
    "            df_next_property_list = get_property_data_from_soup(soup)\n",
    "            # If the new DataFrame is equal to the previous one, stop checking further indices\n",
    "            if df_prev_property_list.equals(df_next_property_list):\n",
    "                print('Property list repeated. Stopping index iteration.')\n",
    "                break\n",
    "            else:\n",
    "                # Append the new property list to main property list and store to check against next one\n",
    "                print('Got {} properties.'.format(df_next_property_list.shape[0]))\n",
    "                df_property = df_property.append(df_next_property_list)\n",
    "                df_prev_property_list = df_next_property_list\n",
    "    # Save collected property data to disk\n",
    "    df_property.to_pickle('EdinburghPropertiesRaw.p')\n",
    "# Report number of properties in raw web scarping result\n",
    "print('Collected total of {} properties from RightMove.'.format(df_property.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format `df_property` DataFrame and keep only the essential information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property sale price samples remaining after filtering the data: 1914\n"
     ]
    }
   ],
   "source": [
    "# Define function for extracting number of bedrooms and\n",
    "# general property type from raw property type data\n",
    "def get_bedrooms_and_type(raw_property_type):\n",
    "    pos = raw_property_type.find(' bedroom ')\n",
    "    raw_property_type = raw_property_type.replace(' bedroom ', ' ')\n",
    "    bedrooms = raw_property_type[:pos].strip()\n",
    "    property_type = raw_property_type[pos:].strip()\n",
    "    \n",
    "    return bedrooms, property_type\n",
    "\n",
    "# Reindex DataFrame\n",
    "df_property.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df_property.drop_duplicates(keep='first', inplace=True)\n",
    "# Reindex DataFrame\n",
    "df_property.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Find property_type 'Studio flat' and set it to 1 bedroom flat\n",
    "idx_studio_flat = df_property['property_type'] == 'Studio flat'\n",
    "df_property['property_type'].loc[idx_studio_flat] = '1 bedroom flat'\n",
    "\n",
    "# Remove properties for which property_type is not in correct format\n",
    "indices = [i for i, x in enumerate(df_property['property_type']) if not (' bedroom ' in x)]\n",
    "df_property.drop(indices, axis=0, inplace=True)\n",
    "# Reindex DataFrame\n",
    "df_property.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Extract number of bedrooms and general property type from property_type values\n",
    "bedrooms, property_type = zip(*[get_bedrooms_and_type(x) for x in df_property['property_type']])\n",
    "df_property['bedrooms'] = list(map(int, bedrooms))\n",
    "df_property['property_type'] = property_type\n",
    "\n",
    "# Rename all flat-like property_types to flats\n",
    "func = lambda x: 'flat' if 'flat' in x or 'apartment' in x or 'penthouse' in x else x\n",
    "df_property['property_type'] = df_property['property_type'].apply(func)\n",
    "# Rename all house-like property_types to house\n",
    "func = lambda x: 'house' if 'house' in x or 'villa' in x or 'duplex' in x or 'bungalow' in x or 'cottage' in x else x\n",
    "df_property['property_type'] = df_property['property_type'].apply(func)\n",
    "\n",
    "# Remove all other property_types than flat or house\n",
    "idx = (df_property['property_type'] != 'flat') & (df_property['property_type'] != 'house')\n",
    "df_property.drop(df_property[idx].index, axis=0, inplace=True)\n",
    "# Reindex DataFrame\n",
    "df_property.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Only keep postcode from address\n",
    "func = lambda x: ' '.join(x.split()[-2:])\n",
    "df_property['address'] = df_property['address'].apply(func)\n",
    "# Rename address column to postcode\n",
    "df_property.rename(columns={'address': 'postcode'}, inplace=True)\n",
    "\n",
    "# Print remaining number of properties\n",
    "print('Property sale price samples remaining after filtering the data: {}'.format(df_property.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add longitude and latitude data into `df_property` based on postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property sale price samples remaining that have \n",
      "latitude and logitude values: 1906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>postcode</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>property_type</th>\n",
       "      <th>price</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31 Dec 2018</td>\n",
       "      <td>EH9 1PN</td>\n",
       "      <td>2</td>\n",
       "      <td>flat</td>\n",
       "      <td>£220,000</td>\n",
       "      <td>55.935498</td>\n",
       "      <td>-3.179898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28 Dec 2018</td>\n",
       "      <td>EH8 7HW</td>\n",
       "      <td>2</td>\n",
       "      <td>flat</td>\n",
       "      <td>£251,500</td>\n",
       "      <td>55.952520</td>\n",
       "      <td>-3.146224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28 Dec 2018</td>\n",
       "      <td>EH30 9LE</td>\n",
       "      <td>5</td>\n",
       "      <td>house</td>\n",
       "      <td>£512,760</td>\n",
       "      <td>55.988611</td>\n",
       "      <td>-3.385420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28 Dec 2018</td>\n",
       "      <td>EH8 7EB</td>\n",
       "      <td>3</td>\n",
       "      <td>house</td>\n",
       "      <td>£268,379</td>\n",
       "      <td>55.954279</td>\n",
       "      <td>-3.154108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27 Dec 2018</td>\n",
       "      <td>EH5 1ER</td>\n",
       "      <td>2</td>\n",
       "      <td>flat</td>\n",
       "      <td>£255,000</td>\n",
       "      <td>55.980068</td>\n",
       "      <td>-3.215696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  postcode  bedrooms property_type     price   latitude  \\\n",
       "0  31 Dec 2018   EH9 1PN         2          flat  £220,000  55.935498   \n",
       "1  28 Dec 2018   EH8 7HW         2          flat  £251,500  55.952520   \n",
       "2  28 Dec 2018  EH30 9LE         5         house  £512,760  55.988611   \n",
       "3  28 Dec 2018   EH8 7EB         3         house  £268,379  55.954279   \n",
       "4  27 Dec 2018   EH5 1ER         2          flat  £255,000  55.980068   \n",
       "\n",
       "   longitude  \n",
       "0  -3.179898  \n",
       "1  -3.146224  \n",
       "2  -3.385420  \n",
       "3  -3.154108  \n",
       "4  -3.215696  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge on latitude and longitude values\n",
    "df_property = df_property.merge(df_postcodes, how='left', on='postcode')\n",
    "# Drop rows where latitude and longitude were not available for postcode\n",
    "df_property.dropna(inplace=True)\n",
    "# Reindex DataFrame\n",
    "df_property.reset_index(drop=True, inplace=True)\n",
    "# # Drop postcode column\n",
    "# df_property.drop('postcode', axis='columns', inplace=True)\n",
    "print('Property sale price samples remaining that have \\n' + \n",
    "      'latitude and logitude values: {}'.format(df_property.shape[0]))\n",
    "df_property.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
