{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Edinburgh Postcode table that contains latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urlretrieve ('https://www.doogal.co.uk/AdministrativeAreasCSV.ashx?district=S12000036', 'EdinburghPostcodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function the extract data for properties from a BeautifulSoup of a html webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_type_from_sold_property_page(http_address):\n",
    "    soup = BeautifulSoup(get(http_address).text, 'html.parser')\n",
    "    return soup.find(id='propertydetails').find_all('h2')[1].text\n",
    "\n",
    "\n",
    "def get_property_data_from_soup(soup):\n",
    "    # Extract data from the http soup\n",
    "    date = []\n",
    "    address = []\n",
    "    bedrooms = []\n",
    "    price = []\n",
    "    property_type = []\n",
    "    for soup_property in soup.find_all(class_='soldDetails'):\n",
    "        # Skip properties for which there is no link to post on RightMove website\n",
    "        if not soup_property.find(class_='soldAddress').has_attr('href'):\n",
    "            continue\n",
    "        else:\n",
    "            property_http_address = soup_property.find(class_='soldAddress')['href']\n",
    "        # Skip properties for which there is no number of bedrooms information\n",
    "        if len(soup_property.find(class_='noBed').text) == 0:\n",
    "            continue\n",
    "        # Collect data for the property\n",
    "        date.append(soup_property.find(class_='soldDate').text)\n",
    "        address.append(soup_property.find(class_='soldAddress').text)\n",
    "        bedrooms.append(soup_property.find(class_='noBed').text)\n",
    "        price.append(soup_property.find(class_='soldPrice').text)\n",
    "        # Attempt to collect property type\n",
    "        try:\n",
    "            property_type.append(get_property_type_from_sold_property_page(property_http_address))        \n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            raise\n",
    "        except:\n",
    "            property_type.append('')\n",
    "            print('Error when collecting property type.')\n",
    "            print(sys.exc_info()[0])\n",
    "    # Format data into pandas.DataFrame\n",
    "    df = pd.DataFrame({'date': date, \n",
    "                       'address': address, \n",
    "                       'bedrooms': bedrooms, \n",
    "                       'property_type': property_type, \n",
    "                       'price': price}, \n",
    "                      columns=['date', 'address', 'bedrooms', 'property_type', 'price'])\n",
    "    # Sort the DataFrame by date as well as address\n",
    "    df.sort_values(['date', 'address'], ascending=[False, True], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class to manage web scraping rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "\n",
    "class RateManager(object):\n",
    "    \n",
    "    def __init__(self, min_interval, max_interval):\n",
    "        \"\"\"\n",
    "        min_interval - float - minimum delay between calls (in seconds)\n",
    "        max_interval - float - maximum delay between calls before notification (in seconds)\n",
    "        \"\"\"\n",
    "        self.min_interval = min_interval\n",
    "        self.max_interval = max_interval\n",
    "        self.checkpoint = None\n",
    "        \n",
    "    def continue_when_ready(self, sleep_interval=0.1, print_interval=False):\n",
    "        # This is in case of first call to continue_when_ready\n",
    "        if self.checkpoint is None:\n",
    "            self.checkpoint = time()\n",
    "            return None\n",
    "        # Check if max_interval has been surpassed\n",
    "        if time() - self.checkpoint > self.max_interval:\n",
    "            if print_interval:\n",
    "                print('Interval duration: {}'.format(time() - self.checkpoint))\n",
    "            self.checkpoint = time()\n",
    "            return 'timeout'\n",
    "        # If not over max_interval, wait until min_interval is reached\n",
    "        if print_interval:\n",
    "            print('Interval duration: {}'.format(time() - self.checkpoint))\n",
    "        while time() - self.checkpoint < self.min_interval:\n",
    "            sleep(sleep_interval)\n",
    "        self.checkpoint = time()\n",
    "        return 'intime'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire residential property sales prices from RightMove.\n",
    "\n",
    "There are likely duplicates in the resulting DataFrame. These will be dealt with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the http addresses for different areas of interest in Edinburgh\n",
    "http_addresses = {\n",
    "    'Stockbridge': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E66977&searchLocation=Stockbridge&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "    'NewTown': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E79909&searchLocation=New+Town&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "    'Morningside': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E86881&searchLocation=Morningside&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "    'EdinburghNorth': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E93604&searchLocation=Edinburgh+North&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "    'EdinburghEast': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E93601&searchLocation=Edinburgh+East&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "    'EdinburghWest': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E93613&searchLocation=Edinburgh+West&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "    'EdinburghSouth': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E93610&searchLocation=Edinburgh+South&propertyType=3&year=2&referrer=listChangeCriteria', \n",
    "    'Edinburgh': 'https://www.rightmove.co.uk/house-prices/detail.html?country=scotland&locationIdentifier=REGION%5E475&searchLocation=Edinburgh&propertyType=3&year=2&referrer=listChangeCriteria'\n",
    "    }\n",
    "\n",
    "# Specify in-line function for suffix that specifies property list page index\n",
    "http_index_suffix = lambda index: '&index={}'.format(index)\n",
    "\n",
    "# Specify indices to work through\n",
    "indices = list(range(0, 1025, 25))\n",
    "\n",
    "# Create empty pandas.DataFrame to append new data to\n",
    "df_property = pd.DataFrame({'date': [], \n",
    "                            'address': [], \n",
    "                            'bedrooms': [], \n",
    "                            'property_type': [], \n",
    "                            'price': []}, \n",
    "                           columns=['date', 'address', 'bedrooms', 'property_type', 'price'])\n",
    "\n",
    "# Use RateManager to avoid overwhelming the website\n",
    "rate_manager = RateManager(min_interval=3, max_interval=10)\n",
    "max_timeouts = 10\n",
    "timeout_count = 0\n",
    "\n",
    "# Loop through all http addresses of different areas and all possible page indices\n",
    "df_prev_property_list = pd.DataFrame({})\n",
    "for http_address in [http_addresses[x] for x in http_addresses]:\n",
    "    for index in indices:\n",
    "        full_http_address = http_address + http_index_suffix(index)\n",
    "        print('Visiting webpage:\\n' + full_http_address)\n",
    "        # Make sure webpage is not visited too often and that it is not blocking\n",
    "        if rate_manager.continue_when_ready(print_interval=True) == 'timeout':\n",
    "            timeout_count += 1\n",
    "            if timeout_count > max_timeouts:\n",
    "                raise RuntimeError('Too many timeouts.')\n",
    "        # Get website html as BeautifulSoup\n",
    "        soup = BeautifulSoup(get(full_http_address).text, 'html.parser')\n",
    "        # Check if there is a property price data list on this page\n",
    "        if len(soup.find_all(class_='soldDetails')) == 0:\n",
    "            print('No properties listed on this page. Stopping index iteration.')\n",
    "            break\n",
    "        df_next_property_list = get_property_data_from_soup(soup)\n",
    "        # If the new DataFrame is equal to the previous one, stop checking further indices\n",
    "        if df_prev_property_list.equals(df_next_property_list):\n",
    "            print('Property list repeated. Stopping index iteration.')\n",
    "            break\n",
    "        else:\n",
    "            # Append the new property list to main property list and store to check against next one\n",
    "            print('Got {} properties.'.format(df_next_property_list.shape[0]))\n",
    "            df_property = df_property.append(df_next_property_list)\n",
    "            df_prev_property_list = df_next_property_list\n",
    "\n",
    "# Save collected property data to disk\n",
    "df_property.to_pickle('EdinburghPropertiesRaw.p')\n",
    "print('Collected total of {} properties.'.format(df_property.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
